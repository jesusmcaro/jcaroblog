{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (1287805114.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    - date: 2024-01-10\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "- title: The Virtues of a Programming your ETL Pipeline using a Fluent API\n",
    "- author: Jesus Caro\n",
    "- date: 2024-01-10\n",
    "- category: python\n",
    "- tags: docker, vscode, github, codespaces, development containers, poetry, venv\n",
    "- Subcells: [3,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from fablr.dataframes import Fablr\n",
    "from datetime import datetime as dt\n",
    "from fablr.sample_assets.artists import artists as artists_list\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "fablr = Fablr()\n",
    "fablr.set_seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id   first_name  last_name                       email  last_login  \\\n",
      "0       23356      Kristen      Davis   michaelholmes@example.org  2023-08-14   \n",
      "1       49263         John   Campbell          qdixon@example.net  2023-01-22   \n",
      "2      101846     Kimberly    Mcclain     christina51@example.com  2023-01-22   \n",
      "3      155790      Shannon    Johnson       richard39@example.com  2023-04-02   \n",
      "4       45003        Ricky     Harper     lanerebecca@example.org  2023-09-07   \n",
      "...       ...          ...        ...                         ...         ...   \n",
      "9995   195033    Gabrielle      Kline    leechristian@example.org  2023-02-01   \n",
      "9996   115447  Christopher   Robinson    nicholashart@example.com  2023-09-20   \n",
      "9997   195040     Jennifer     Miller   ramirezdaniel@example.com  2023-07-12   \n",
      "9998   185801        Linda  Wilkinson     gibsonjason@example.net  2023-09-06   \n",
      "9999    64472        Ariel      Lewis  keithschroeder@example.org  2023-06-03   \n",
      "\n",
      "     subscription_tier  \n",
      "0                Prime  \n",
      "1             Standard  \n",
      "2                Prime  \n",
      "3                Prime  \n",
      "4             Standard  \n",
      "...                ...  \n",
      "9995             Prime  \n",
      "9996             Prime  \n",
      "9997             Prime  \n",
      "9998          Standard  \n",
      "9999          Standard  \n",
      "\n",
      "[10000 rows x 6 columns]\n",
      "      user_id first_name last_name                      email  last_login  \\\n",
      "0       23356    Kristen     Davis  michaelholmes@example.org  2023-08-14   \n",
      "1       49263       John  Campbell         qdixon@example.net  2023-01-22   \n",
      "2      101846   Kimberly   Mcclain    christina51@example.com  2023-01-22   \n",
      "3      155790    Shannon   Johnson      richard39@example.com  2023-04-02   \n",
      "4       45003      Ricky    Harper    lanerebecca@example.org  2023-09-07   \n",
      "...       ...        ...       ...                        ...         ...   \n",
      "9994   192845       Cody      Hale       brandy39@example.net  2023-06-03   \n",
      "9995    93915      Ruben   Mcclure          wkemp@example.org  2023-06-17   \n",
      "9996    11397      Linda  Robinson     jennifer18@example.net  2023-10-04   \n",
      "9997    53379    Matthew  Anderson     dylanjohns@example.net  2023-07-05   \n",
      "9998   119841     Alison     Scott  nicholehodges@example.org  2023-03-08   \n",
      "\n",
      "     subscription_tier                                               hash  \n",
      "0                Prime  58cc145e5b9febd36a5037e70f8866e7455982b3eca6b5...  \n",
      "1             Standard  08ca2e97defb2a29e30548345db8f7c68cbfe045d2c368...  \n",
      "2                Prime  656da1522ea3ae4cc84baea93f2de95f06447f4c42a61d...  \n",
      "3                Prime  4b96f9211ff094b216d1a7e6af381dc8ee16a6c8c79a18...  \n",
      "4             Standard  02fa12dfb03dc748e21ba81cb6caba66ea51c81a66f210...  \n",
      "...                ...                                                ...  \n",
      "9994          Standard  91d0f6efb226e42e7a971b9d7b987f87212a82c8641643...  \n",
      "9995          Standard  0cd0f1c2b1bbe42dafcddd1a5a387c2b84efb70738a30c...  \n",
      "9996             Prime  696d9363dc5a99999e82bc3f4a78d98b96bd5367c4c268...  \n",
      "9997             Prime  ed5ea6939428afb8f78f77a60026ae7b1843c5d77073a8...  \n",
      "9998             Prime  1a4f174ca6aef442da7e4945ad61ccdd5e6d9d9ef6fd77...  \n",
      "\n",
      "[9984 rows x 7 columns]\n",
      "      user_id first_name last_name                      email  last_login  \\\n",
      "0       23356    Kristen     Davis  michaelholmes@example.org  2023-08-14   \n",
      "1       49263       John  Campbell         qdixon@example.net  2023-01-22   \n",
      "2      101846   Kimberly   Mcclain    christina51@example.com  2023-01-22   \n",
      "3      155790    Shannon   Johnson      richard39@example.com  2023-04-02   \n",
      "4       45003      Ricky    Harper    lanerebecca@example.org  2023-09-07   \n",
      "...       ...        ...       ...                        ...         ...   \n",
      "9993   188450    Michele    Nelson        hsexton@example.org  2023-11-14   \n",
      "9994   107132      Wendy   Elliott         fwelch@example.org  2023-03-06   \n",
      "9996    75562    Brandon    Potter  rodriguezbeth@example.org  2023-10-04   \n",
      "9997    23678    Theresa     Brown      matthew42@example.com  2023-01-22   \n",
      "9998    19170      Devin   Merritt        cspence@example.org  2023-11-23   \n",
      "\n",
      "     subscription_tier                                               hash  \n",
      "0                Prime  58cc145e5b9febd36a5037e70f8866e7455982b3eca6b5...  \n",
      "1             Standard  08ca2e97defb2a29e30548345db8f7c68cbfe045d2c368...  \n",
      "2                Prime  656da1522ea3ae4cc84baea93f2de95f06447f4c42a61d...  \n",
      "3                Prime  4b96f9211ff094b216d1a7e6af381dc8ee16a6c8c79a18...  \n",
      "4             Standard  02fa12dfb03dc748e21ba81cb6caba66ea51c81a66f210...  \n",
      "...                ...                                                ...  \n",
      "9993          Standard  1bd0f24d9f0d59ef12dae9d4e4cd45742827cb680b1ca8...  \n",
      "9994             Prime  a95ba10fd2bcdf8d1170ff9a89847c9775d3ede4683bea...  \n",
      "9996             Prime  36e990c204ad31851b92eb8dc65542d5f6695bf346cad8...  \n",
      "9997          Standard  4c134d5aac5b0a55d9bc0129304e185069bfb60900dcc5...  \n",
      "9998             Prime  5bb96bfcc0d8ce33b4c52da788fdb13c56e00315880a6b...  \n",
      "\n",
      "[9998 rows x 7 columns]\n",
      "      user_id first_name  last_name                         email  last_login  \\\n",
      "0       23356    Kristen      Davis     michaelholmes@example.org  2023-08-14   \n",
      "1       49263       John   Campbell            qdixon@example.net  2023-01-22   \n",
      "2      101846   Kimberly    Mcclain       christina51@example.com  2023-01-22   \n",
      "3      155790    Shannon    Johnson         richard39@example.com  2023-04-02   \n",
      "4       45003      Ricky     Harper       lanerebecca@example.org  2023-09-07   \n",
      "...       ...        ...        ...                           ...         ...   \n",
      "9995    75562    Brandon     Potter     rodriguezbeth@example.org  2023-10-04   \n",
      "9996    23678    Theresa      Brown         matthew42@example.com  2023-01-22   \n",
      "9997    19170      Devin    Merritt           cspence@example.org  2023-11-23   \n",
      "9998   128487    Gregory  Gutierrez            gboyer@example.net  2023-07-31   \n",
      "9999    14944   Jennifer   Williams  michellerobinson@example.org  2023-04-27   \n",
      "\n",
      "     subscription_tier                                               hash  \n",
      "0                Prime  58cc145e5b9febd36a5037e70f8866e7455982b3eca6b5...  \n",
      "1             Standard  08ca2e97defb2a29e30548345db8f7c68cbfe045d2c368...  \n",
      "2                Prime  656da1522ea3ae4cc84baea93f2de95f06447f4c42a61d...  \n",
      "3                Prime  4b96f9211ff094b216d1a7e6af381dc8ee16a6c8c79a18...  \n",
      "4             Standard  02fa12dfb03dc748e21ba81cb6caba66ea51c81a66f210...  \n",
      "...                ...                                                ...  \n",
      "9995             Prime  36e990c204ad31851b92eb8dc65542d5f6695bf346cad8...  \n",
      "9996          Standard  4c134d5aac5b0a55d9bc0129304e185069bfb60900dcc5...  \n",
      "9997             Prime  5bb96bfcc0d8ce33b4c52da788fdb13c56e00315880a6b...  \n",
      "9998          Standard  f84ccf75ea8d45319784cb26b8358acc363c7b58731b39...  \n",
      "9999             Prime  56fdd26be54c9d55149cac1fd81efd28bd42ba99476427...  \n",
      "\n",
      "[10000 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/pypoetry/virtualenvs/jcaroblog-eKDzoHOT-py3.11/lib/python3.11/site-packages/fablr/dataframes.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(\n",
      "/home/jovyan/.cache/pypoetry/virtualenvs/jcaroblog-eKDzoHOT-py3.11/lib/python3.11/site-packages/fablr/dataframes.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(\n",
      "/home/jovyan/.cache/pypoetry/virtualenvs/jcaroblog-eKDzoHOT-py3.11/lib/python3.11/site-packages/fablr/dataframes.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           event_id             event_name  event_date  event_location  \\\n",
      "0    eid_ykjP-68711              Bob Dylan  2020-02-19   Hooperchester   \n",
      "1    eid_Todl-21745                   Muse  2023-05-04     New Carolyn   \n",
      "2    eid_ZatJ-84380        The Stone Roses  2021-06-15    Douglasburgh   \n",
      "3    eid_DuHa-46969              New Order  2019-10-23     Marquezberg   \n",
      "4    eid_izHt-43743                  Queen  2021-06-18   Christinebury   \n",
      "..              ...                    ...         ...             ...   \n",
      "795  eid_JuOH-18681                   Blur  2021-06-15     Fisherhaven   \n",
      "796  eid_DgHZ-43911             The Eagles  2021-06-21       Millstown   \n",
      "797  eid_WcUT-41297                   KISS  2023-01-03  New Kellyshire   \n",
      "798  eid_rfmg-04567           Led Zeppelin  2020-07-21   Fernandezberg   \n",
      "799  eid_rUct-34589  Red Hot Chili Peppers  2020-09-07  East Geneburgh   \n",
      "\n",
      "    event_result  \n",
      "0      cancelled  \n",
      "1      cancelled  \n",
      "2     succesfull  \n",
      "3     succesfull  \n",
      "4      cancelled  \n",
      "..           ...  \n",
      "795   succesfull  \n",
      "796   succesfull  \n",
      "797   succesfull  \n",
      "798   succesfull  \n",
      "799    cancelled  \n",
      "\n",
      "[800 rows x 5 columns]\n",
      "        ticket_no        event_id  user_id  total_charged  surcharge\n",
      "0      3893058728  eid_VbOr-43754     3647         653.74      11.99\n",
      "1       769124028  eid_nFHi-83562   104070         696.76       5.99\n",
      "2      1305237448  eid_ezew-25794   147247         163.12      11.99\n",
      "3      3555972263  eid_JzSI-65945    62482         733.16       0.00\n",
      "4      2810655759  eid_pddy-51538    84105         568.86       5.99\n",
      "...           ...             ...      ...            ...        ...\n",
      "99995   974323790  eid_MGwZ-99907    16160         294.85      11.99\n",
      "99996  2401783927  eid_FbDg-06066    80568         370.88       0.00\n",
      "99997  2204012328  eid_aPdD-51194   100670         591.54       5.99\n",
      "99998  6392879627  eid_FbDg-06066   103586          32.75      11.99\n",
      "99999  4733930500  eid_OhVI-72438    42825         183.19       5.99\n",
      "\n",
      "[100000 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Resolved attribute(s) event_date#14 missing from event_id#266,event_name#267,event_date#268,event_location#269,event_result#270 in operator !Project [event_id#266, event_name#267, cast(event_date#14 as date) AS event_date#276, event_location#269, event_result#270]. Attribute(s) with the same name appear in the operation: event_date. Please check if the right attribute(s) are used.;\n!Project [event_id#266, event_name#267, cast(event_date#14 as date) AS event_date#276, event_location#269, event_result#270]\n+- LogicalRDD [event_id#266, event_name#267, event_date#268, event_location#269, event_result#270], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m tickets \u001b[39m=\u001b[39m fablr\u001b[39m.\u001b[39mgenerate_dataframe(\u001b[39m100000\u001b[39m, tickets_dict)\n\u001b[1;32m     36\u001b[0m users_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mcreateDataFrame(users)\n\u001b[0;32m---> 37\u001b[0m events_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mcreateDataFrame(events)\u001b[39m.\u001b[39;49mwithColumn(\u001b[39m'\u001b[39;49m\u001b[39mevent_date\u001b[39;49m\u001b[39m'\u001b[39;49m, events_df[\u001b[39m'\u001b[39;49m\u001b[39mevent_date\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mcast(\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     38\u001b[0m tickets_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mcreateDataFrame(tickets)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jcaroblog-eKDzoHOT-py3.11/lib/python3.11/site-packages/pyspark/sql/dataframe.py:5170\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5166\u001b[0m     \u001b[39mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5167\u001b[0m         error_class\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNOT_COLUMN\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5168\u001b[0m         message_parameters\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39marg_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marg_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(col)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m   5169\u001b[0m     )\n\u001b[0;32m-> 5170\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mwithColumn(colName, col\u001b[39m.\u001b[39;49m_jc), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jcaroblog-eKDzoHOT-py3.11/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/jcaroblog-eKDzoHOT-py3.11/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Resolved attribute(s) event_date#14 missing from event_id#266,event_name#267,event_date#268,event_location#269,event_result#270 in operator !Project [event_id#266, event_name#267, cast(event_date#14 as date) AS event_date#276, event_location#269, event_result#270]. Attribute(s) with the same name appear in the operation: event_date. Please check if the right attribute(s) are used.;\n!Project [event_id#266, event_name#267, cast(event_date#14 as date) AS event_date#276, event_location#269, event_result#270]\n+- LogicalRDD [event_id#266, event_name#267, event_date#268, event_location#269, event_result#270], false\n"
     ]
    }
   ],
   "source": [
    "### Create dataframes\n",
    "date_format = '%Y-%m-%d'\n",
    "users_dict = {\n",
    "  'user_id': {'provider':'random_int', 'kwargs':{\"min\":0, \"max\": 2e5}},\n",
    "  'first_name': {'provider': 'first_name', 'kwargs': {}},\n",
    "  'last_name': {'provider': 'last_name', 'kwargs': {}},\n",
    "  'email': {'provider': 'email', 'kwargs': {}},\n",
    "  'last_login': {'provider': 'date_between_dates',\n",
    "                 'kwargs': {'date_start': dt.strptime('2023-01-01', date_format), 'date_end': dt.strptime('2023-12-01', date_format)}},\n",
    "  'subscription_tier' : {'provider': 'sample_list',\n",
    "                         'kwargs':{'list':[\"Prime\", \"Standard\"], 'unique': False}}\n",
    "}\n",
    "users = fablr.generate_dataframe(10000, users_dict, primary_keys=['user_id'])\n",
    "\n",
    "\n",
    "events_dict = {\n",
    "    'event_id': {'provider':'bothify', 'kwargs':{'text': 'eid_????-#####'}},\n",
    "    'event_name': {'provider': 'sample_list', 'kwargs': {'list': artists_list}},\n",
    "    'event_date': {'provider': 'date_between_dates',\n",
    "                 'kwargs': {'date_start': dt.strptime('2019-01-01', date_format), 'date_end': dt.strptime('2023-12-01', date_format)}},\n",
    "    'event_location': {'provider': 'city', 'kwargs': {}},\n",
    "    'event_result': {'provider': 'sample_list', 'kwargs': {'list': ['succesfull']*91 + ['cancelled']*9}},\n",
    "}\n",
    "events = fablr.generate_dataframe(800, events_dict)\n",
    "\n",
    "tickets_dict = {\n",
    "    'ticket_no': {'provider':'random_int', 'unique': True, 'kwargs':{\"min\":0, \"max\": 1e10}},\n",
    "    'event_id': {'provider':'sample_dataframe', 'kwargs': {'df': events, 'column': 'event_id'}},\n",
    "    'user_id': {'provider':'sample_dataframe', 'kwargs': {'df': users, 'column': 'user_id'}},\n",
    "    'total_charged': {'provider': 'random_float', 'kwargs': {'min': 20, 'max': 800}},\n",
    "    'surcharge': {'provider': 'sample_list', 'kwargs': {'list': [5.99]*20 + [11.99]*15 + [0]*15}},\n",
    "}\n",
    "\n",
    "tickets = fablr.generate_dataframe(100000, tickets_dict)\n",
    "\n",
    "users_df = spark.createDataFrame(users)\n",
    "events_df = spark.createDataFrame(events).withColumn('event_date', events_df['event_date'].cast('date'))\n",
    "tickets_df = spark.createDataFrame(tickets)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: The Fluent Interface Pattern"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week marked a new chapter in my career. I started a new job as a Data Engineer for Synaptiq building ETL pipelines that feed into ML and AI models. Looking back at my (nearly) year long career at Sequoia (A First American Startup),\n",
    "I cant help but feel grateful for the opportunity to have worked with such a talented team. I learned a lot about Data Engineering. One of the most undervalues things I learned in that role \n",
    "came in the form of a design preference from my Team lead. Often he would ask me to write additional transforms and apply them in pipelines using the **Fluent API**. I googled it, and there is some literature on the topic, but it's \n",
    "a bit technical, and not really to the point. So I decided to write this post to explain what it is, and some benefits with leveraging this design by using a simple illustration in the form of a sample Pyspark pipeline. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a `Fluent Interface?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fluent interface is a design pattern that allows you to chain methods (and in our case transformations) together in a way that is easy to read and understand. Leveraging this design pattern can make your code more readable, and easier to maintain. Those are not the only benefits, using a fluent interface, along with \"unit transformations\" can make your code more testable. \n",
    "\n",
    "Let's look at an example. In the following example, I have created a simple data model for a ticket reseller. The data model is simple, and contains three tables:\n",
    "\n",
    "- Users: The users table contains information about the users of the platform.\n",
    "- Tickets: The tickets table contains information about the tickets that were purchased by each user.\n",
    "- Events: The events table contains information about the events that the tickets are for.\n",
    "\n",
    "An ERD for the data model is shown below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD](images/fluent_api/hot_tickets_erd.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll be using building our ETL pipeline in pyspark. Pyspark has a neat method called `.transform()` that allows you to apply a transform to a dataframe. This method returns a new dataframe, and allows you to chain transformations together. First, let's print out our dataframes to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users dataframe\n",
      "+-------+----------+---------+--------------------+----------+-----------------+\n",
      "|user_id|first_name|last_name|email               |last_login|subscription_tier|\n",
      "+-------+----------+---------+--------------------+----------+-----------------+\n",
      "|13726  |Joseph    |Mack     |daniel06@example.net|2023-08-07|Standard         |\n",
      "|89338  |Melissa   |Moore    |ann32@example.org   |2023-06-19|Prime            |\n",
      "|156657 |Nicholas  |Smith    |cgarcia@example.org |2023-09-17|Prime            |\n",
      "+-------+----------+---------+--------------------+----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Tickets dataframe\n",
      "+----------+--------------+-------+-------------+---------+\n",
      "|ticket_no |event_id      |user_id|total_charged|surcharge|\n",
      "+----------+--------------+-------+-------------+---------+\n",
      "|9957101488|eid_MPlU-54882|118225 |513.25       |11.99    |\n",
      "|967991971 |eid_JvhR-30831|141011 |250.34       |0.0      |\n",
      "|5662180548|eid_TqKz-24766|168873 |46.43        |0.0      |\n",
      "+----------+--------------+-------+-------------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Events dataframe\n",
      "+--------------+------------------+----------+--------------+------------+\n",
      "|event_id      |event_name        |event_date|event_location|event_result|\n",
      "+--------------+------------------+----------+--------------+------------+\n",
      "|eid_BRqB-98032|Coldplay          |2022-12-24|Morganhaven   |succesfull  |\n",
      "|eid_IoFo-28520|James Taylor      |2020-11-16|Port Vanessa  |succesfull  |\n",
      "|eid_KTrZ-91270|The Rolling Stones|2023-04-11|Lake Yolanda  |succesfull  |\n",
      "+--------------+------------------+----------+--------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Users dataframe\")\n",
    "users_df.show(3, False)\n",
    "print(\"Tickets dataframe\")\n",
    "tickets_df.show(3, False)\n",
    "print(\"Events dataframe\")\n",
    "events_df.show(3, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our task is to build an ETL pipeline that will return the number of tickets sold for events between two dates, as well as the total revenue generated for those events, by subscription tier.\n",
    "\n",
    "Let's start by listing the transformations, so that we can build our ETL pipeline in a fluent way.\n",
    "\n",
    "- 1.) Filter events between two dates, that were marked `successful` and not cancelled (these were refunded)\n",
    "- 2.) Join events and tickets on event_id to grab the total charge and surcharge.\n",
    "- 3.) Join events and users on user_id to grab the subscription tiers.\n",
    "- 4.) Group by events, and subscription tier and sum to get the total revenue and surcharge for subscription tier `standard`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import DateType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "def filter_events(start_date, end_date, result) -> DataFrame:\n",
    "    def _df(df) -> DataFrame:\n",
    "        return (\n",
    "                df.filter(F.col('event_date')\n",
    "                          .between(start_date, end_date))\n",
    "                  .filter(F.col('event_result') == 'succesfull')\n",
    "        )\n",
    "    return _df\n",
    "\n",
    "def agg_revenue(df: DataFrame) -> DataFrame:\n",
    "    return df.groupBy(['event_id','event_name', 'subscription_tier']).agg({'total_charged': 'sum', 'surcharge': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[event_id: string, event_name: string, event_date: date, event_location: string, event_result: string]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.transform(filter_events(start_date='2021-01-01', end_date='2021-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_revenue(\n",
    "    events: DataFrame,\n",
    "    tickets: DataFrame,\n",
    "    users: DataFrame,\n",
    "    start_date: DateType,\n",
    "    end_date: DateType,\n",
    "    event_result: str,\n",
    "    subscription_tier: str) -> DataFrame:\n",
    "    \n",
    "    events.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _df():\n",
    "    return \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__._df()>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jcaroblog-eKDzoHOT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9aa6aee49d60ccd2bd71d375990fb075770fa95a679ee9c2bddb85a9c9a1ba2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
